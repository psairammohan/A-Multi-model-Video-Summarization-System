{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVqswAjqmD-R",
        "outputId": "0f21be7b-d3be-4620-a058-e1619c5991b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.2.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7xN0YB9mEvx",
        "outputId": "9e0a7238-56be-4b3b-9568-8c491bbb52a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyTube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwtazKEjnH15",
        "outputId": "9a710b5e-24f1-4ec6-c2b3-cebe2d279278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyTube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import whisper\n",
        "from langdetect import detect\n",
        "from pytube import YouTube\n",
        "\n",
        "\n",
        "\n",
        "# Function to open a file\n",
        "def startfile(fn):\n",
        "    os.system('open %s' % fn)\n",
        "\n",
        "\n",
        "# Function to create and open a txt file\n",
        "def create_and_open_txt(text, filename):\n",
        "    # Create and write the text to a txt file\n",
        "    with open(filename, \"w\") as file:\n",
        "        file.write(text)\n",
        "    startfile(filename)\n",
        "\n",
        "\n",
        "# Ask user for the YouTube video URL\n",
        "url = input(\"Enter the YouTube video URL: \")\n",
        "\n",
        "# Create a YouTube object from the URL\n",
        "yt = YouTube(url)\n",
        "\n",
        "# Get the audio stream\n",
        "audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "\n",
        "# Download the audio stream\n",
        "output_path = \"YoutubeAudios\"\n",
        "filename = \"audio.mp3\"\n",
        "audio_stream.download(output_path=output_path, filename=filename)\n",
        "\n",
        "print(f\"Audio downloaded to {output_path}/{filename}\")\n",
        "\n",
        "# Load the base model and transcribe the audio\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"YoutubeAudios/audio.mp3\")\n",
        "transcribed_text = result[\"text\"]\n",
        "print(transcribed_text)\n",
        "\n",
        "# Detect the language\n",
        "language = detect(transcribed_text)\n",
        "print(f\"Detected language: {language}\")\n",
        "\n",
        "# Create and open a txt file with the text\n",
        "create_and_open_txt(transcribed_text, f\"output_{language}.txt\")\n",
        "\n",
        "# Finding the accuracy based on Blue score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHoaxG8kmJQo",
        "outputId": "ded7a434-033f-4c0e-81a6-676bd06c9d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube video URL: https://www.youtube.com/watch?v=8xg3vE8Ie_E\n",
            "Audio downloaded to YoutubeAudios/audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " We were both young when I first saw you. I closed my eyes and the flashback starts I'm standing there On the balcony and summer air See the lights, see the party, the bargams See you make your way through the crowd and say hello Little did I know Let it you know we owe you a throw in pavels And my daddy said stay away from Juliet And I was crying on the staircase begging you please don't go And I said, you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh, because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said, you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So be your same baby try to tell me how to feel This love is difficult but it's a real Don't be afraid we'll make it out of this mess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh, because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said, you need to take me somewhere we can be alone Save me, I've been feeling so alone I keep waiting for you, but you never comest this in my head I don't know what to think He nailed to the ground and fall I'll ring and set marry me Juliet So you love her, how to be alone I love you and that's all I really know I'm talking to your dad go pick out a wire dress Yes, it's a love story, baby, just say Yes, oh, oh, oh, oh, oh We love young people first, I do\n",
            "Detected language: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from pytube import YouTube\n",
        "\n",
        "\n",
        "# Function to ensure directory exists for saving frames\n",
        "def create_dir(path):\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "output_path = \"DownloadedVideos\"\n",
        "\n",
        "# Ask user for the YouTube video URL\n",
        "url = input(\"Enter the YouTube video URL: \")\n",
        "\n",
        "yt = YouTube(url)\n",
        "\n",
        "# Get the highest resolution video stream\n",
        "video_stream = yt.streams.filter(progressive=True).order_by('resolution').desc().first()\n",
        "\n",
        "video_stream.download(output_path=output_path, filename=\"video.mp4\")\n",
        "\n",
        "\n",
        "# Create a VideoCapture object from the URL\n",
        "#cap = cv2.VideoCapture(url)\n",
        "\n",
        "cap = cv2.VideoCapture(os.path.join(output_path, \"video.mp4\"))\n",
        "\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "  print(\"Error opening video!\")\n",
        "  exit()\n",
        "\n",
        "# Define directory and filename format for frames\n",
        "frame_dir = \"Extracted_Frames_test2\"\n",
        "create_dir(frame_dir)  # Create directory if it doesn't exist\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "  # Capture frame-by-frame\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  # Check if a frame was captured\n",
        "  if not ret:\n",
        "    print(\"No more frames to capture!\")\n",
        "    break\n",
        "\n",
        "  # Save frame as JPEG with increasing number\n",
        "  if frame_count % 50 == 0:\n",
        "    filename = os.path.join(frame_dir, f\"frame_{frame_count}.jpg\")\n",
        "    cv2.imwrite(filename, frame)\n",
        "\n",
        "  # Increase frame count\n",
        "  frame_count += 1\n",
        "\n",
        "  # Optionally, limit the number of frames to extract\n",
        "  # if frame_count >= 100:  # Extract only first 100 frames (example)\n",
        "  #   break\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Extracted {frame_count} frames and saved to {frame_dir}\")\n"
      ],
      "metadata": {
        "id": "dgqcWcjImWV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2b25d6-543d-48c6-bc15-1385f44dee05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube video URL: https://www.youtube.com/watch?v=8xg3vE8Ie_E\n",
            "No more frames to capture!\n",
            "Extracted 5670 frames and saved to Extracted_Frames_test2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for total_frame in range(frame_count):\n",
        "  if total_frame % 50 == 0:\n",
        "    print(total_frame)\n"
      ],
      "metadata": {
        "id": "qN-p5XV3nkq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f03c3c9-3023-4503-e6e7-44d7fa6a636a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "3650\n",
            "3700\n",
            "3750\n",
            "3800\n",
            "3850\n",
            "3900\n",
            "3950\n",
            "4000\n",
            "4050\n",
            "4100\n",
            "4150\n",
            "4200\n",
            "4250\n",
            "4300\n",
            "4350\n",
            "4400\n",
            "4450\n",
            "4500\n",
            "4550\n",
            "4600\n",
            "4650\n",
            "4700\n",
            "4750\n",
            "4800\n",
            "4850\n",
            "4900\n",
            "4950\n",
            "5000\n",
            "5050\n",
            "5100\n",
            "5150\n",
            "5200\n",
            "5250\n",
            "5300\n",
            "5350\n",
            "5400\n",
            "5450\n",
            "5500\n",
            "5550\n",
            "5600\n",
            "5650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64"
      ],
      "metadata": {
        "id": "k0oA2HNBWbgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_api_key = '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'"
      ],
      "metadata": {
        "id": "Al_E09OUbayt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "9lstbeGobj2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8725086-cc3d-4c72-d6a3-15e334de99df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "get_completion = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['generated_text']"
      ],
      "metadata": {
        "id": "aDEek6r9eRPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def integrate_captions(transcribed_text, cleaned_text):\n",
        "  \"\"\"\n",
        "  Integrates captions at punctuation marks or appends at the end.\n",
        "\n",
        "  Args:\n",
        "      transcribed_text: The text transcribed from the audio.\n",
        "      cleaned_text: The text generated from image captions (string or list).\n",
        "\n",
        "  Returns:\n",
        "      A string with the combined text with captions inserted.\n",
        "  \"\"\"\n",
        "  sentences = transcribed_text.split(\".\")\n",
        "  sentences.extend(transcribed_text.split(\"! \"))\n",
        "  sentences.extend(transcribed_text.split(\"? \"))\n",
        "\n",
        "  combined_text = \"\"\n",
        "  for i, sentence in enumerate(sentences):\n",
        "    if sentence and cleaned_text:\n",
        "      # Handle list input for cleaned_text\n",
        "      if isinstance(cleaned_text, list):\n",
        "        # Join the list elements if it's a list\n",
        "        cleaned_text_str = \" \".join(cleaned_text)\n",
        "      else:\n",
        "        # Use the string directly if it's already a string\n",
        "        cleaned_text_str = cleaned_text\n",
        "      combined_text += sentence + \" \" + cleaned_text_str + \" \"\n",
        "      # Reduce cleaned_text for next iteration (if applicable)\n",
        "      if isinstance(cleaned_text, list):\n",
        "        cleaned_text = cleaned_text[:-1]\n",
        "    else:\n",
        "      combined_text += sentence + \" \"\n",
        "\n",
        "  # Add any remaining cleaned text at the end\n",
        "  combined_text += \" \".join(cleaned_text) if isinstance(cleaned_text, list) else cleaned_text\n",
        "\n",
        "  return combined_text.strip()\n"
      ],
      "metadata": {
        "id": "987ht7JTIRYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKzRdHNHxD7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the text file\n",
        "with open('/content/output_en.txt', 'r') as file:\n",
        "    data = file.read()\n",
        "\n",
        "# Split the text based on periods, commas, and question marks\n",
        "split_data_audio = re.split(r'[.,?]', data)\n",
        "\n",
        "# Print the split data\n",
        "for sentence in split_data_audio:\n",
        "    print(sentence.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NHZcXMsw861",
        "outputId": "4b9abc92-63e4-4ad7-cffe-a41622e6d7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We were both young when I first saw you\n",
            "I closed my eyes and the flashback starts I'm standing there On the balcony and summer air See the lights\n",
            "see the party\n",
            "the bargams See you make your way through the crowd and say hello Little did I know Let it you know we owe you a throw in pavels And my daddy said stay away from Juliet And I was crying on the staircase begging you please don't go And I said\n",
            "you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh\n",
            "because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said\n",
            "you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So be your same baby try to tell me how to feel This love is difficult but it's a real Don't be afraid we'll make it out of this mess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh\n",
            "because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said\n",
            "you need to take me somewhere we can be alone Save me\n",
            "I've been feeling so alone I keep waiting for you\n",
            "but you never comest this in my head I don't know what to think He nailed to the ground and fall I'll ring and set marry me Juliet So you love her\n",
            "how to be alone I love you and that's all I really know I'm talking to your dad go pick out a wire dress Yes\n",
            "it's a love story\n",
            "baby\n",
            "just say Yes\n",
            "oh\n",
            "oh\n",
            "oh\n",
            "oh\n",
            "oh We love young people first\n",
            "I do\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Get video captions\n",
        "video_text = \"\"\n",
        "for frame in range(0, frame_count, 100):\n",
        "  if frame % 100 == 0:\n",
        "    image_path = f\"/content/Extracted_Frames_test2/frame_{frame}.jpg\"\n",
        "    text_gen = get_completion(image_path)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "\n",
        "\n",
        "    if text_gen:\n",
        "      for item in text_gen:\n",
        "        cleaned_text = item.get('generated_text', '').strip()\n",
        "        if cleaned_text:\n",
        "          print(cleaned_text)\n",
        "          inputs = processor(text=cleaned_text, images=image, return_tensors=\"pt\", padding=True)\n",
        "          outputs = model(**inputs)\n",
        "          logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
        "          probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
        "          # Assuming probs is the tensor [[0.9949, 0.0051]]\n",
        "          probs_array = probs.detach().numpy()  # Convert the tensor to a NumPy array\n",
        "          value = probs_array[0][0]  # Access the value at index [0][0]\n",
        "          if value > 0.5:\n",
        "            video_text += cleaned_text + \".\"\n",
        "\n",
        "# Combine transcribed text and video captions\n",
        "#combined_text = integrate_captions(transcribed_text, video_text)\n",
        "\n",
        "# Create and open a txt file with the combined text\n",
        "create_and_open_txt(video_text, f\"output_video_{language}.txt\")"
      ],
      "metadata": {
        "id": "H3ejoVP9mXuM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "939d5521-71ec-48e7-b0c5-61ad66fc7ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-647e2df78bab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIPProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openai/clip-vit-base-patch32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openai/clip-vit-base-patch32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3013\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3015\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   3016\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_hub_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     headers = build_hf_headers(\n\u001b[0m\u001b[1;32m   1224\u001b[0m         \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Get auth token to send\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mtoken_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0m_validate_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_write_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mget_token_to_send\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Token is not provided: we get it from local cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mcached_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Case token is explicitly required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py\u001b[0m in \u001b[0;36mget_token\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_token_from_google_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_token_from_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_token_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py\u001b[0m in \u001b[0;36m_get_token_from_google_colab\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0m_GOOGLE_COLAB_SECRET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# thread-safe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_userdata_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     resp = _message.blocking_request(\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;34m'GetSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the text file\n",
        "with open('/content/output_video_en.txt', 'r') as file:\n",
        "    data = file.read()\n",
        "\n",
        "# Split the text based on periods, commas, and question marks\n",
        "split_data_video = re.split(r'[.,?]', data)\n",
        "\n",
        "# Print the split data\n",
        "for sentence in split_data_video:\n",
        "    print(sentence.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rp71uN21gK4",
        "outputId": "a175938d-abac-4819-f4a3-54ebc65a3137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a black background with a white and red flower\n",
            "a woman walking down a sidewalk with a book\n",
            "a man sitting under a tree reading a book\n",
            "a man sitting under a tree reading a book\n",
            "a stone wall with a statue in the middle\n",
            "taylor taylor - i'm a girl\n",
            "a woman in a wedding dress standing on a porch\n",
            "a woman in a dress is leaning against a column\n",
            "a woman in a dress standing on a porch\n",
            "a man in a black coat and white shirt\n",
            "a woman in a dress standing next to another woman\n",
            "a man standing in front of a window\n",
            "a woman in a dress is standing behind columns\n",
            "a man in a suit and tie is talking to a woman\n",
            "a woman in a wedding dress standing on a porch\n",
            "a man and woman dancing together in a room\n",
            "a woman in a white dress standing in front of a building\n",
            "a man and woman dancing in a room\n",
            "a man and woman in formal attire dancing\n",
            "a woman in a wedding dress standing on a balcony\n",
            "taylor taylor and taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor\n",
            "a woman in a dress standing on a porch\n",
            "a man is seen through a window in the jungle\n",
            "a woman in a wedding dress is looking at her phone\n",
            "a woman in a black dress standing in a garden\n",
            "a woman in a black dress standing in a garden\n",
            "a woman in a white dress is standing by a column\n",
            "a woman standing in a doorway with her hand on her face\n",
            "a woman in a white dress is standing in front of a window\n",
            "a woman in a dress is standing behind columns\n",
            "a woman holding a lantern in the woods\n",
            "taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor\n",
            "a woman in a dress holding a lantern\n",
            "a man and woman in a forest\n",
            "a woman in a wedding dress standing outside\n",
            "a woman is standing behind a column\n",
            "a man in a suit and tie standing next to a statue\n",
            "a statue in the middle of a forest\n",
            "a person holding a cherry on a branch\n",
            "taylor taylor - i'm a girl\n",
            "a woman in a wedding dress standing on a porch\n",
            "taylor taylor - i'm a girl\n",
            "a woman in a dress standing in front of a window\n",
            "a woman in a dress is leaning against a column\n",
            "taylor taylor - i'm a girl\n",
            "a woman in a wedding dress is walking through a brick archway\n",
            "a man standing in a field with a white shirt\n",
            "a woman in a white dress walking through a field\n",
            "a couple kissing in a field at sunset\n",
            "a man and woman are kissing in a field\n",
            "a couple kissing in a field at sunset\n",
            "a woman in a white dress is walking through a doorway\n",
            "a man and woman standing next to each other people\n",
            "a woman standing next to a man in a forest\n",
            "a man and woman standing next to each other people\n",
            "a woman in a dress is leaning against a column\n",
            "taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_audio = len(split_data_audio)\n",
        "len_video = len(split_data_video)"
      ],
      "metadata": {
        "id": "GkaBH-0U2va1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gamma = len_video/len_audio\n",
        "print(Gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1GJW1aG3ZGr",
        "outputId": "f9964e83-6207-4027-ed01-88ce9fcce82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.761904761904762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_lists_and_insert(lst1, lst2):\n",
        "    # Calculate gamma\n",
        "    gamma = len(lst1) / len(lst2)\n",
        "\n",
        "    # Convert gamma to an integer\n",
        "    gamma = int(gamma)\n",
        "\n",
        "    # Initialize index and counter\n",
        "    index = 1\n",
        "    counter = 0\n",
        "\n",
        "    # Loop through lst2 and insert elements from lst1 accordingly\n",
        "    while lst2:\n",
        "        # Insert gamma number of elements from lst1 after the first element in lst2\n",
        "        lst2[index:index] = lst1[counter:counter+gamma]\n",
        "        counter += gamma\n",
        "        index += gamma + 1\n",
        "\n",
        "        # If there are remaining elements in lst1, insert them at the end of lst2\n",
        "        if counter >= len(lst1):\n",
        "            lst2.extend(lst1[counter:])\n",
        "            break\n",
        "\n",
        "    return lst2\n",
        "\n",
        "# Example lists\n",
        "list1 = split_data_video\n",
        "list2 = split_data_audio\n",
        "\n",
        "# Merge lists and perform insertion\n",
        "result = merge_lists_and_insert(list1, list2)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRosaoKF73__",
        "outputId": "0d261d92-6645-48c1-a66c-447b686b7562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' We were both young when I first saw you', 'a black background with a white and red flower', 'a woman walking down a sidewalk with a book', \" I closed my eyes and the flashback starts I'm standing there On the balcony and summer air See the lights\", 'a man sitting under a tree reading a book', 'a man sitting under a tree reading a book', ' see the party', 'a stone wall with a statue in the middle', \"taylor taylor - i'm a girl\", \" the bargams See you make your way through the crowd and say hello Little did I know Let it you know we owe you a throw in pavels And my daddy said stay away from Juliet And I was crying on the staircase begging you please don't go And I said\", 'a woman in a wedding dress standing on a porch', 'a woman in a dress is leaning against a column', \" you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh\", 'a woman in a dress standing on a porch', 'a man in a black coat and white shirt', \" because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said\", 'a woman in a dress standing next to another woman', 'a man standing in front of a window', \" you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So be your same baby try to tell me how to feel This love is difficult but it's a real Don't be afraid we'll make it out of this mess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh\", 'a woman in a dress is standing behind columns', 'a man in a suit and tie is talking to a woman', \" because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said\", 'a woman in a wedding dress standing on a porch', 'a man and woman dancing together in a room', ' you need to take me somewhere we can be alone Save me', 'a woman in a white dress standing in front of a building', 'a man and woman dancing in a room', \" I've been feeling so alone I keep waiting for you\", 'a man and woman in formal attire dancing', 'a woman in a wedding dress standing on a balcony', \" but you never comest this in my head I don't know what to think He nailed to the ground and fall I'll ring and set marry me Juliet So you love her\", 'taylor taylor and taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor', 'a woman in a dress standing on a porch', \" how to be alone I love you and that's all I really know I'm talking to your dad go pick out a wire dress Yes\", 'a man is seen through a window in the jungle', 'a woman in a wedding dress is looking at her phone', \" it's a love story\", 'a woman in a black dress standing in a garden', 'a woman in a black dress standing in a garden', ' baby', 'a woman in a white dress is standing by a column', 'a woman standing in a doorway with her hand on her face', ' just say Yes', 'a woman in a white dress is standing in front of a window', 'a woman in a dress is standing behind columns', ' oh', 'a woman holding a lantern in the woods', 'taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor', ' oh', 'a woman in a dress holding a lantern', 'a man and woman in a forest', ' oh', 'a woman in a wedding dress standing outside', 'a woman is standing behind a column', ' oh', 'a man in a suit and tie standing next to a statue', 'a statue in the middle of a forest', ' oh We love young people first', 'a person holding a cherry on a branch', \"taylor taylor - i'm a girl\", ' I do', 'a woman in a wedding dress standing on a porch', \"taylor taylor - i'm a girl\", 'a woman in a dress standing in front of a window', 'a woman in a dress is leaning against a column', \"taylor taylor - i'm a girl\", 'a woman in a wedding dress is walking through a brick archway', 'a man standing in a field with a white shirt', 'a woman in a white dress walking through a field', 'a couple kissing in a field at sunset', 'a man and woman are kissing in a field', 'a couple kissing in a field at sunset', 'a woman in a white dress is walking through a doorway', 'a man and woman standing next to each other people', 'a woman standing next to a man in a forest', 'a man and woman standing next to each other people', 'a woman in a dress is leaning against a column', 'taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example list of strings\n",
        "list_of_strings = [\"Hello\", \"world\", \"this\", \"is\", \"a\", \"test\"]\n",
        "\n",
        "# Join the strings using a space as a separator\n",
        "multi_model_text = \", \".join(result)\n",
        "\n",
        "print(multi_model_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIc2qkfU9Ov4",
        "outputId": "a0f28432-e62a-4e29-d51c-7da1b1810249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " We were both young when I first saw you, a black background with a white and red flower, a woman walking down a sidewalk with a book,  I closed my eyes and the flashback starts I'm standing there On the balcony and summer air See the lights, a man sitting under a tree reading a book, a man sitting under a tree reading a book,  see the party, a stone wall with a statue in the middle, taylor taylor - i'm a girl,  the bargams See you make your way through the crowd and say hello Little did I know Let it you know we owe you a throw in pavels And my daddy said stay away from Juliet And I was crying on the staircase begging you please don't go And I said, a woman in a wedding dress standing on a porch, a woman in a dress is leaning against a column,  you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh, a woman in a dress standing on a porch, a man in a black coat and white shirt,  because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said, a woman in a dress standing next to another woman, a man standing in front of a window,  you need to take me somewhere we can be alone I'll be waiting all there's something to do is run You will be the prince and I'll be the princess It's a love story baby just say yes So be your same baby try to tell me how to feel This love is difficult but it's a real Don't be afraid we'll make it out of this mess It's a love story baby just say yes So I sneak out to the garden to see you We keep quiet because we're dead if you so close your eyes Just keep this town for a little while Oh, a woman in a dress is standing behind columns, a man in a suit and tie is talking to a woman,  because you were only your eye was a scarlet letter And my daddy said stay away from Juliet But you were everything to me I was begging you please don't go And I said, a woman in a wedding dress standing on a porch, a man and woman dancing together in a room,  you need to take me somewhere we can be alone Save me, a woman in a white dress standing in front of a building, a man and woman dancing in a room,  I've been feeling so alone I keep waiting for you, a man and woman in formal attire dancing, a woman in a wedding dress standing on a balcony,  but you never comest this in my head I don't know what to think He nailed to the ground and fall I'll ring and set marry me Juliet So you love her, taylor taylor and taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor, a woman in a dress standing on a porch,  how to be alone I love you and that's all I really know I'm talking to your dad go pick out a wire dress Yes, a man is seen through a window in the jungle, a woman in a wedding dress is looking at her phone,  it's a love story, a woman in a black dress standing in a garden, a woman in a black dress standing in a garden,  baby, a woman in a white dress is standing by a column, a woman standing in a doorway with her hand on her face,  just say Yes, a woman in a white dress is standing in front of a window, a woman in a dress is standing behind columns,  oh, a woman holding a lantern in the woods, taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor,  oh, a woman in a dress holding a lantern, a man and woman in a forest,  oh, a woman in a wedding dress standing outside, a woman is standing behind a column,  oh, a man in a suit and tie standing next to a statue, a statue in the middle of a forest,  oh We love young people first, a person holding a cherry on a branch, taylor taylor - i'm a girl,  I do, a woman in a wedding dress standing on a porch, taylor taylor - i'm a girl, a woman in a dress standing in front of a window, a woman in a dress is leaning against a column, taylor taylor - i'm a girl, a woman in a wedding dress is walking through a brick archway, a man standing in a field with a white shirt, a woman in a white dress walking through a field, a couple kissing in a field at sunset, a man and woman are kissing in a field, a couple kissing in a field at sunset, a woman in a white dress is walking through a doorway, a man and woman standing next to each other people, a woman standing next to a man in a forest, a man and woman standing next to each other people, a woman in a dress is leaning against a column, taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor taylor, \n"
          ]
        }
      ]
    }
  ]
}